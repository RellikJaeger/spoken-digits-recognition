{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_FILE = \"train.csv\"\n",
    "TEST_CSV_FILE = \"test.csv\"\n",
    "RODOLFO_CSV_FILE = \"rodolfo.csv\"\n",
    "ANKUR_CSV_FILE = \"ankur.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FIUhv3GI8FOF",
    "outputId": "5adb2545-0d54-4494-c1bb-6fbb9f69ed45"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extractWavFeatures(soundFilesFolder, csvFileName):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "    print('CSV Header: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    genres = '1 2 3 4 5 6 7 8 9 0'.split()\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        number = f'{soundFilesFolder}/{filename}'\n",
    "        y, sr = librosa.load(number, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        #file = open('data.csv', 'a', newline='')\n",
    "        #with file:\n",
    "        #    writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"End of extractWavFeatures\")\n",
    "\n",
    "# comment these lines if you already have train.csv and test.csv files\n",
    "#extractWavFeatures(\"../data/recordings/train\", TRAIN_CSV_FILE)\n",
    "#extractWavFeatures(\"../data/recordings/test\", TEST_CSV_FILE)\n",
    "#extractWavFeatures(\"../data/recordings/rodolfo\", RODOLFO_CSV_FILE)\n",
    "#extractWavFeatures(\"../data/recordings/ankur\", ANKUR_CSV_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "_TZXrWYiNqCj",
    "outputId": "7d1d926e-64fa-4855-df66-207a97778915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.112672         741.829081          758.492178  1438.494873   \n",
      "1  0.090344         635.610880          670.336296  1160.452403   \n",
      "2  0.091456         667.786694          732.606545  1257.180176   \n",
      "3  0.087751         712.304185          731.292437  1449.104818   \n",
      "4  0.096603         844.363886          777.868127  1569.583263   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0            0.034023 -295.578461  189.853683 -19.606564   6.078507   \n",
      "1            0.033458 -339.148743  204.005249  -7.485526  14.297898   \n",
      "2            0.033268 -327.507416  195.596924  -3.994768  21.315840   \n",
      "3            0.035916 -320.809937  200.023743  -8.186146  12.661074   \n",
      "4            0.049465 -315.801300  195.674118 -13.324564   3.544238   \n",
      "\n",
      "       mfcc5  ...     mfcc12    mfcc13     mfcc14     mfcc15    mfcc16  \\\n",
      "0  22.067095  ... -25.725817 -5.172223  -8.323026 -10.299589 -0.144793   \n",
      "1  20.885136  ... -23.196365 -1.290891  -5.515564 -15.416287  0.405876   \n",
      "2  18.372593  ... -18.677113 -3.098450 -10.447586 -10.053793  3.248016   \n",
      "3  15.654718  ... -20.832333 -1.118007  -6.681235 -11.685319  2.010999   \n",
      "4  12.279986  ... -18.158249  6.031695  -6.353736 -15.983871  1.465030   \n",
      "\n",
      "      mfcc17     mfcc18    mfcc19     mfcc20  number  \n",
      "0  -9.017329  -4.569392  2.881349 -15.627436       0  \n",
      "1  -3.624587 -11.204143 -0.096359  -6.751650       0  \n",
      "2 -11.686995 -10.726046  6.857377  -9.067446       0  \n",
      "3  -5.946658  -6.905020  4.136240  -9.614882       0  \n",
      "4  -5.109472  -8.666434  5.026890  -5.346444       0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "test.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.095394         756.450712          761.875940  1463.941148   \n",
      "1  0.040176         791.046914         1039.695939  2027.709961   \n",
      "2  0.006984         958.934867          941.639039  2084.106445   \n",
      "3  0.071547         759.877794          899.957003  1427.553489   \n",
      "4  0.030382         968.793389         1024.834851  1911.968994   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  \\\n",
      "0            0.037296 -328.263885  180.479416  -0.485355  15.525293   \n",
      "1            0.031440 -385.602570  189.328186 -37.268154  59.937920   \n",
      "2            0.040039 -542.812622  217.971329 -62.197266  21.537390   \n",
      "3            0.030429 -355.530396  204.388977 -20.676432  26.671131   \n",
      "4            0.045654 -376.499390  237.137833 -59.964413  37.715607   \n",
      "\n",
      "       mfcc5  ...     mfcc12     mfcc13     mfcc14     mfcc15     mfcc16  \\\n",
      "0  20.992447  ... -15.426966   7.284101  -6.443027 -13.377846  -2.407696   \n",
      "1  45.049831  ... -31.051588   3.420474  -9.762264 -11.220519  12.306476   \n",
      "2  37.756233  ... -26.797358   5.341060 -12.159102 -14.180812   9.346475   \n",
      "3  15.797892  ... -18.198524   4.029843 -10.552087 -21.039103  -5.634320   \n",
      "4  21.510382  ... -21.805593  13.740063  -6.738161  -9.305484  13.205662   \n",
      "\n",
      "      mfcc17     mfcc18    mfcc19     mfcc20  number  \n",
      "0 -12.902534 -10.437113 -1.025342 -15.457672       0  \n",
      "1  -5.082399  -3.775387  9.707520  -8.757109       0  \n",
      "2 -10.899978  -9.715154  5.997578 -12.574761       0  \n",
      "3 -14.788965 -11.016036 -1.313916 -16.993853       1  \n",
      "4 -11.917943  -7.877903  9.777577 -10.397771       1  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "rodolfo.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.007524        1729.852822         1697.177456  3335.083008   \n",
      "1  0.042267        1756.732890         1591.145144  3224.274170   \n",
      "2  0.034325        1638.553404         1419.867746  2881.522576   \n",
      "3  0.041617        1307.690455         1268.966124  2266.681060   \n",
      "4  0.026950        1463.055869         1332.628126  2526.729424   \n",
      "\n",
      "   zero_crossing_rate       mfcc1       mfcc2     mfcc3      mfcc4     mfcc5  \\\n",
      "0            0.119689 -571.201111  102.074806 -4.757813   4.653874  0.856112   \n",
      "1            0.085034 -419.510712   67.985924  6.938254  -0.141423 -0.643495   \n",
      "2            0.078590 -454.969482  101.746574  3.870497 -10.591887 -0.051776   \n",
      "3            0.066951 -403.129547  109.022636  9.162525  -7.512613 -4.656820   \n",
      "4            0.083769 -439.182556   68.049164  9.268405   0.831647  1.076083   \n",
      "\n",
      "   ...     mfcc12    mfcc13     mfcc14     mfcc15     mfcc16    mfcc17  \\\n",
      "0  ... -17.603579 -7.749345  -8.494217 -10.231359  -7.123421 -4.127722   \n",
      "1  ... -10.983952 -4.160895  -5.037401  -7.922421  -6.600300 -3.122108   \n",
      "2  ... -11.108720 -8.321853 -11.982990 -13.489149  -7.467219 -3.019025   \n",
      "3  ... -13.367341 -6.735057  -9.012393 -13.058663 -11.855878 -6.285484   \n",
      "4  ... -15.347961 -4.601788  -1.226764  -6.549379 -12.401876 -8.910025   \n",
      "\n",
      "     mfcc18    mfcc19    mfcc20  number  \n",
      "0 -3.750175 -3.249759 -1.587886       0  \n",
      "1 -0.328377 -1.220566 -2.917431       0  \n",
      "2 -2.409389 -3.132482 -1.475702       1  \n",
      "3 -0.736577 -3.117511 -2.887637       1  \n",
      "4 -3.216097 -0.957792 -0.697212       2  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "ankur.csv will be preprocessed\n",
      "Preprocessing is finished\n",
      "       rmse  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
      "0  0.018532        2694.900238         2361.025999  5036.823760   \n",
      "1  0.006844        4050.306025         2689.667335  6987.657335   \n",
      "2  0.017122        3595.192685         2451.007929  5909.141602   \n",
      "3  0.015548        3437.973763         2536.889008  6185.633829   \n",
      "4  0.045170        3865.948693         2508.392241  6667.001448   \n",
      "\n",
      "   zero_crossing_rate       mfcc1      mfcc2     mfcc3      mfcc4      mfcc5  \\\n",
      "0            0.206161 -450.656525  82.424110  2.283102   6.844382 -10.762469   \n",
      "1            0.211661 -639.549927  36.153034  6.020615   2.252873  -3.648098   \n",
      "2            0.203555 -514.030334  52.352474  1.688708  -3.347528  -9.164898   \n",
      "3            0.224783 -506.653687  45.819801 -2.089325  18.366461  -7.491622   \n",
      "4            0.208889 -445.323273  45.922962 -7.976539   7.129772 -11.679096   \n",
      "\n",
      "   ...    mfcc12    mfcc13    mfcc14    mfcc15    mfcc16    mfcc17    mfcc18  \\\n",
      "0  ... -6.552861 -3.256115 -3.792228 -4.877125 -3.078096 -2.986307 -1.336789   \n",
      "1  ... -3.044816 -2.013772 -1.361247 -3.493830 -3.453226 -1.724725 -0.815734   \n",
      "2  ... -5.833296 -4.842553 -5.305068  0.477596 -3.898500  0.124318 -1.315186   \n",
      "3  ... -9.514052 -1.988709 -5.471163 -0.866976 -4.227705 -2.284665  1.621064   \n",
      "4  ... -4.126058  1.314522 -4.063213  1.440987 -4.430447 -0.169125 -1.374548   \n",
      "\n",
      "     mfcc19    mfcc20  number  \n",
      "0 -2.764679  0.948654       0  \n",
      "1 -4.107770 -1.373948       1  \n",
      "2 -2.949817 -2.703465       2  \n",
      "3 -4.374322 -0.135026       3  \n",
      "4 -2.388803 -0.550287       4  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading a dataset and convert file name to corresbonding umnber\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def preProcessData(csvFileName):\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data = pd.read_csv(csvFileName)\n",
    "    data['number'] = data['filename'].str[:1]\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "    data = data.drop(['chroma_stft'],axis=1)\n",
    "    data.shape\n",
    "\n",
    "    print(\"Preprocessing is finished\")\n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)\n",
    "rodolfoData = preProcessData(RODOLFO_CSV_FILE)\n",
    "ankurData = preProcessData(ANKUR_CSV_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPbfaLTrap87"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEy6oG8RQmnN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029,)\n",
      "(441,)\n",
      "(30,)\n",
      "(20,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y = trainData.iloc[:, -1]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "X_rodolfo = np.array(rodolfoData.iloc[:, :-1], dtype = float)\n",
    "y_rodolfo = rodolfoData.iloc[:, -1]\n",
    "\n",
    "X_ankur = np.array(ankurData.iloc[:, :-1], dtype = float)\n",
    "y_ankur = ankurData.iloc[:, -1]\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n",
    "print(y_rodolfo.shape)\n",
    "print(y_ankur.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1o-OccqP5Ax",
    "outputId": "c93e0d6f-f5c0-4208-b0e5-7ecba885cddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 25)\n",
      "(441, 25)\n",
      "(30, 25)\n",
      "(20, 25)\n",
      "(10, 25)\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform( X_train )\n",
    "X_val = scaler.transform( X_val )\n",
    "X_test = scaler.transform( X_test )\n",
    "X_rodolfo = scaler.transform( X_rodolfo )\n",
    "X_ankur = scaler.transform( X_ankur )\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(X_rodolfo.shape)\n",
    "print(X_ankur.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "Q06tYXcdQZFp",
    "outputId": "8ab73b51-7592-450c-b152-8746e2f11b87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Creating a Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# model 1\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "mJH2-yaTRHxV",
    "outputId": "bef3ccf8-289d-4202-bdc2-86f3b16d3bac"
   },
   "outputs": [],
   "source": [
    "# Learning Process of a model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTcYgQO8Z5u-"
   },
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "colab_type": "code",
    "id": "iBDSdjwbaNzg",
    "outputId": "5c9ac6d9-a441-4fde-e157-803437bb0250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1029 samples, validate on 441 samples\n",
      "Epoch 1/50\n",
      "1029/1029 [==============================] - 0s 138us/step - loss: 2.1103 - accuracy: 0.2653 - val_loss: 1.7832 - val_accuracy: 0.5873\n",
      "Epoch 2/50\n",
      "1029/1029 [==============================] - 0s 26us/step - loss: 1.6653 - accuracy: 0.5355 - val_loss: 1.3591 - val_accuracy: 0.6939\n",
      "Epoch 3/50\n",
      "1029/1029 [==============================] - 0s 29us/step - loss: 1.2946 - accuracy: 0.6297 - val_loss: 0.9986 - val_accuracy: 0.7506\n",
      "Epoch 4/50\n",
      "1029/1029 [==============================] - 0s 32us/step - loss: 1.0031 - accuracy: 0.6939 - val_loss: 0.7322 - val_accuracy: 0.8549\n",
      "Epoch 5/50\n",
      "1029/1029 [==============================] - 0s 30us/step - loss: 0.8306 - accuracy: 0.7405 - val_loss: 0.5667 - val_accuracy: 0.8685\n",
      "Epoch 6/50\n",
      "1029/1029 [==============================] - 0s 31us/step - loss: 0.6813 - accuracy: 0.7813 - val_loss: 0.4312 - val_accuracy: 0.9206\n",
      "Epoch 7/50\n",
      "1029/1029 [==============================] - 0s 30us/step - loss: 0.5389 - accuracy: 0.8397 - val_loss: 0.3581 - val_accuracy: 0.9184\n",
      "Epoch 8/50\n",
      "1029/1029 [==============================] - 0s 29us/step - loss: 0.4701 - accuracy: 0.8571 - val_loss: 0.2954 - val_accuracy: 0.9297\n",
      "Epoch 9/50\n",
      "1029/1029 [==============================] - 0s 31us/step - loss: 0.3833 - accuracy: 0.8941 - val_loss: 0.2488 - val_accuracy: 0.9365\n",
      "Epoch 10/50\n",
      "1029/1029 [==============================] - 0s 31us/step - loss: 0.3301 - accuracy: 0.9077 - val_loss: 0.2020 - val_accuracy: 0.9546\n",
      "Epoch 11/50\n",
      "1029/1029 [==============================] - 0s 29us/step - loss: 0.3099 - accuracy: 0.9038 - val_loss: 0.1758 - val_accuracy: 0.9524\n",
      "Epoch 12/50\n",
      "1029/1029 [==============================] - 0s 30us/step - loss: 0.2774 - accuracy: 0.9164 - val_loss: 0.1755 - val_accuracy: 0.9524\n",
      "Epoch 13/50\n",
      "1029/1029 [==============================] - 0s 28us/step - loss: 0.2595 - accuracy: 0.9184 - val_loss: 0.1512 - val_accuracy: 0.9637\n",
      "Epoch 14/50\n",
      "1029/1029 [==============================] - 0s 27us/step - loss: 0.2395 - accuracy: 0.9310 - val_loss: 0.1273 - val_accuracy: 0.9728\n",
      "Epoch 15/50\n",
      "1029/1029 [==============================] - 0s 30us/step - loss: 0.2143 - accuracy: 0.9397 - val_loss: 0.1201 - val_accuracy: 0.9683\n",
      "Epoch 16/50\n",
      "1029/1029 [==============================] - 0s 29us/step - loss: 0.1913 - accuracy: 0.9466 - val_loss: 0.1233 - val_accuracy: 0.9615\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Train with early stopping to avoid overfitting\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,\n",
    "                    batch_size=128, \n",
    "                    callbacks=[es])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "z3nvtYKVa5HD",
    "outputId": "b858b37f-8e47-4cb4-a737-ef960246254b"
   },
   "outputs": [],
   "source": [
    "# plot training history\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "HSVxu84pRgZa",
    "outputId": "eb9242c9-7bff-4d54-a58c-60a915aad7d2"
   },
   "outputs": [],
   "source": [
    "print('\\n# TEST DATA #\\n')\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Predection \n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "\n",
    "print(\"y[0]: \"+ y_test[0])\n",
    "print(\"y[10]: \"+ y_test[10])\n",
    "print(\"y[20]: \"+ y_test[20])\n",
    "\n",
    "print(model.predict(X_test[0:1]))\n",
    "print(model.predict(X_test[10:11]))\n",
    "print(model.predict(X_test[20:21]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# RODOLFO DATA #\\n')\n",
    "score = model.evaluate(X_rodolfo, y_rodolfo)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Predection \n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "\n",
    "print(\"y[0]: \"+ y_rodolfo[0])\n",
    "print(\"y[5]: \"+ y_rodolfo[5])\n",
    "print(\"y[15]: \"+ y_rodolfo[15])\n",
    "\n",
    "print(model.predict(X_rodolfo[0:1]))\n",
    "print(model.predict(X_rodolfo[5:6]))\n",
    "print(model.predict(X_rodolfo[15:16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# ANKUR DATA #\\n')\n",
    "score = model.evaluate(X_ankur, y_ankur)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# Predection \n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "\n",
    "print(\"y[0]: \"+ y_ankur[0])\n",
    "print(\"y[5]: \"+ y_ankur[5])\n",
    "print(\"y[8]: \"+ y_ankur[8])\n",
    "\n",
    "print(model.predict(X_ankur[0:1]))\n",
    "print(model.predict(X_ankur[5:6]))\n",
    "print(model.predict(X_ankur[8:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sound-regnize-Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
